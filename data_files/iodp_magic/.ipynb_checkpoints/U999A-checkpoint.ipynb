{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reduction for paleomagnetic data aboard the JOIDES Resolution\n",
    "\n",
    "This notebook is for people wanting to download and manipulate data from an IODP Expedition using data in the LIMS Online Repository.  The basic procedure is as follows.  This notebook will guide you through the process step-by-step.   \n",
    "\n",
    "- Import the required python packages and set up the desired directory structure for each HOLE. \n",
    "- Download the Section Summary table and put the .csv file in the HOLE working directory\n",
    "- Download the Sample Report table for any discrete samples taken (select Sample Type - CUBE and Test code PMAG) and put them in the HOLE working directory\n",
    "- Download the SRM data for the hole and put them in the SRM working directory in the HOLE working directory \n",
    "- Download the SRM discrete measurement data for the hole and put them in the SRM_discrete sample working directory.\n",
    "- Download the JR6 data and put them in the JR6 working directory\n",
    "- Download the KLY4S data and put them in the KLY4S working directory.\n",
    "- If you want to edit the archive half data for coring or lithologic disturbances:\n",
    "- Download the core disturbance info from Desklogic\n",
    "    - go to the Desklogic computer station and open DeskLogic (little yellow square)\n",
    "    - select the 'macroscopic' template\n",
    "    - select sample: hole, Archive, section half\n",
    "    - download\n",
    "    - export: include classification, Data and save on the Desktop\n",
    "    - if the network drives are not available, right click on the double square icon on bar\n",
    "    - switch the login profile to scientist and login with OES credentials (user name/email password)\n",
    "    - choose scientist and map the drives.  they should be now available to windows explorer\n",
    "    - copy to your HOLE working directory.  \n",
    "- If you want to use Xray information to edit your archive half data:  fill in  the XRAY disturbance summary file and put it into the HOLE working directory \\[template is in data_files/iodp_magic\\]\n",
    "\n",
    "To start processing data from a single HOLE:\n",
    "\n",
    "- Duplicate this notebook with the HOLE name (e.g., U999A) by first making a copy, then renaming it under the 'File' menu.  Follow the instructions below. \n",
    "\n",
    "For HELP:   \n",
    "    - for help on options in any python function, you can type:\n",
    "    help(MODULE.FUNCTION)  in the cell below.    For example click on the cell below for information on how to use convert.iodp_samples_csv.  This works for any python function.  \n",
    "    - email ltauxe@ucsd.edu.  Incluede a description of your problem, a screen shot of the error if appropriate and an example data file that is causing the difficulty (be mindful of embargo issues).  \n",
    "\n",
    "For a worked example (using FAKE data, see data_files/iodp_magic/U999A.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Preliminaries](#preliminaries) : import required packages, set up directory structure and set file names\n",
    "- [Make sample tables](#sample) : parse downloaded sample table to standard format\n",
    "- [Archive measurements](#archives) : parse downloaded srm archive measurements and perform editing functions\n",
    "- [Discrete sample measurements](#discretes) : parse downloaded discrete sample data\n",
    "- [Downhole plots](#plots) : make downhole plots of remanence\n",
    "- [Anisotropy of magnetic susceptibility](#aniso) : plots of AMS\n",
    "- [Prepare files for uploading to MagIC](#upload) : you can upload data to the MagIC database as a private contribution.  Then when you have published your data, you can activate your contribution with the DOI of your publication.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preliminaries'></a>\n",
    "\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "- In the cell below, edit the HOLE name  and set the HOLE latitude and longitude  where HOLE stands for the hole name.  The cell below will do this for you. \n",
    "\n",
    "- edit the file names as you download them from LORE\n",
    "\n",
    "- Every time you open this notebook, you must click on the cell below and then click 'Run' in the menu above to execute it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a bunch of packages for use in the notebook\n",
    "import pmagpy.pmag as pmag # a bunch of PmagPy modules\n",
    "import pmagpy.pmagplotlib as pmagplotlib\n",
    "import pmagpy.ipmag as ipmag\n",
    "import pmagpy.contribution_builder as cb\n",
    "from pmagpy import convert_2_magic as convert # conversion scripts for many lab formats\n",
    "from pmagpy import  iodp_funcs as iodp_funcs # functions for dealing with LIMS data\n",
    "import matplotlib.pyplot as plt # our plotting buddy\n",
    "import numpy as np # the fabulous NumPy package\n",
    "import pandas as pd # and of course Pandas\n",
    "%matplotlib inline \n",
    "from importlib import reload\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "meas_files,spec_files,samp_files,site_files=[],[],[],[] # holders for magic file names\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Modify these for your expedition\n",
    "exp_name,exp_description=\"IODP Expedition 999\",\"Test Data\" # e.g., 'IODP Expedition 382','Iceberg Alley'\n",
    "\n",
    "# Edit these for each hole.  In the following, HOLE refers to the current hole. \n",
    "hole=\"U999A\" # e.g., U999A\n",
    "\n",
    "# edit these for the current hole - get it from Hole summary on LORE\n",
    "hole_lat,hole_lon=0+0/60,0+0/60 # e.g., -57+26.5335/60,-43+21.4723/60 \n",
    "gad_inc=pmag.pinc(hole_lat) # geocentric axial dipole inclination for hole\n",
    "\n",
    "demag_step=0.010 # choose the demagnetization step (in tesla) for downhole plots \n",
    "\n",
    "\n",
    "# set up the directory structure for this hole\n",
    "# these are default locations and variables - do not change them. \n",
    "jr6_dir=hole+'/JR6_data'\n",
    "kly4s_dir=hole+'/KLY4S_data'\n",
    "srm_archive_dir=hole+'/SRM_archive_data'\n",
    "srm_discrete_dir=hole+'/SRM_discrete_data'\n",
    "magic_dir=hole+'/'+hole+'_MagIC'\n",
    "dscr_file=\"\" # if no discrete samples, this stays blank\n",
    "\n",
    "\n",
    "\n",
    "# set up the directory structure\n",
    "if hole:          # checks if the hole name has been set. \n",
    "    if hole in os.listdir(): # checks if the directory structure exists, otherwise this will create it\n",
    "        os.mkdir(hole)\n",
    "        os.mkdir(jr6_dir)\n",
    "        os.mkdir(kly4s_dir)\n",
    "        os.mkdir(srm_archive_dir)\n",
    "        os.mkdir(srm_discrete_dir)\n",
    "        os.mkdir(magic_dir)\n",
    "        os.mkdir('Figures')\n",
    "\n",
    "#After mkdir has been run,  you can \n",
    "# 1) download all the files you need  \n",
    "# 2) put them in the correct folders as instructed below.  Set the file names here:\n",
    "# 3) edit the file names for the downloaded files. \n",
    "\n",
    "\n",
    "# Put these downloaded file into the HOLE directory (after mkdir has been executed)\n",
    "\n",
    "# required for downhole direction plot.  Put the file in the HOLE directory\n",
    "section_summary_file=\"Section Summary_17_5_2019.csv\" # set this to the downloaded summary file (e.g., \"Section Summary_15_5_2019.csv\")\n",
    "if section_summary_file: # add the path to the summary file, if set.  \n",
    "    summary_file=hole+'/'+section_summary_file \n",
    "# required for downhole AMS plot.   Put the file in the HOLE directory\n",
    "core_summary_file=\"Core Summary_18_5_2019.csv\" # set this to the downloaded Core summary file (e.g., \"Core Summary_15_4_2019.csv\")\n",
    "# required for unpacking LIMS discrete sample data. Put the file in the HOLE directory\n",
    "samp_file=\"samples_17_5_2019.csv\" # set this to   your sample file (e.g., samp_file='samples_5_4_2019.csv' )\n",
    "\n",
    "\n",
    "# Put these files into the designated subdirectories in the HOLE directory:\n",
    "# required for unpacking SRM archive measurements file.  It should be in HOLE/SRM_archive_data/\n",
    "srm_archive_file=\"srmsection_17_5_2019.csv\"   # set this to your srm archive file from LIMS (e.g., \"srmsection_1_4_2019.csv\")\n",
    "\n",
    "# required for unpacking SRM discrete measurements file.  It should be in HOLE/SRM_discrete_data/\n",
    "srm_discrete_file= 'srmdiscrete_17_5_2019.csv' # SRM discrete measurements file (e.g., \"srmdiscrete_7_4_2019.csv\")\n",
    "# required for unpacking SRM discrete measurements with OFFLINE TREATMENTS.  Put in:  HOLE/SRM_archive_data/\n",
    "# NB: you also need the srm_discrete_file set\n",
    "dscr_ex_file='' # SRM discrete extended file (e.g., \"ex-srm_26_4_2019.csv\")\n",
    "\n",
    "# needed for unpacking JR-6 measurement data. Put the file in HOLE/JR6_data/ directory\n",
    "jr6_file='spinner_17_5_2019.csv' # JR6 data file from LORE (e.g., \"spinner_1_4_2019.csv\")\n",
    "\n",
    "# required for unpackying Kappabridge data.  be sure to download the expanded file from LORE.  \n",
    "# Put it in HOLE/KLY4S_data/   \n",
    "kly4s_file='ex-kappa_17_5_2019.csv' # set this to the downloaded file (e.g., \"ex-kappa_15_4_2019.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sample'></a>\n",
    "\n",
    "\n",
    "\n",
    "### Make the sample tables\n",
    "\n",
    "- Download the Sample Report and Section Summary tables (when available) for the HOLE from the LIMS online repository at http://web.ship.iodp.tamu.edu/LORE/ and save them as csv files.    \n",
    "- Put the two .csv files in the HOLE directory created above.   \n",
    "- Edit the name of the sample .csv  file in prelimaries cell and the 'secondary depth' column that you selected when downloading (the default is CSF-B as below) in the cell below. \n",
    "- Execute the cell to  populate the MagIC meta-data tables.  The depth information ends up in the lims_sites.txt table in the HOLE_MagIC directory, for example and gets used to create downhole plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create the samples, sites, and locations tables for the hole.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make sure the sample file is in your HOLE directory and the filename set in the Preliminaries \n",
    "# Note:  this program will not run if the file is in use\n",
    "\n",
    "if samp_file:\n",
    "    \n",
    "    comp_depth_key='Top depth CSF-B (m)'\n",
    "# do the heavy lifting: \n",
    "    convert.iodp_samples_csv(samp_file,input_dir_path=hole,spec_file='lims_specimens.txt',\\\n",
    "                         samp_file='lims_samples.txt',site_file='lims_sites.txt',\\\n",
    "                         dir_path=magic_dir,comp_depth_key=comp_depth_key,\\\n",
    "                exp_name=exp_name,exp_desc=exp_description,lat=hole_lat,\\\n",
    "                lon=hole_lon)\n",
    "# this collects the file names that were created so they can be combined with others, e.g., those\n",
    "# from the archive half measurements which are not in the sample table. \n",
    "    if 'lims_specimens.txt' not in spec_files:spec_files.append('lims_specimens.txt')\n",
    "    if 'lims_samples.txt' not in samp_files:samp_files.append('lims_samples.txt')\n",
    "    if 'lims_sites.txt' not in site_files:site_files.append('lims_sites.txt')\n",
    "# do it again to make copies for use with demag_gui\n",
    "    convert.iodp_samples_csv(samp_file,input_dir_path=hole,\\\n",
    "                         dir_path=magic_dir,comp_depth_key=comp_depth_key,\\\n",
    "                exp_name=exp_name,exp_desc=exp_description,lat=hole_lat,\\\n",
    "                lon=hole_lon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='archives'></a>\n",
    "\n",
    "\n",
    "### Convert the SRM archive half data for the Hole\n",
    "\n",
    "- download data for a single hole from LORE as a csv file. edit the file name in the preliminaries cell\n",
    "- put the file into the HOLE/SRM_archive_data directory in the HOLE directory\n",
    "- edit the composite depth column header (comp_depth_key) if desired.\n",
    "- if you have been busy measuring archives, writing the measurement files can take awhile so be patient.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Fill in the name of your srm archive half measruement file (e.g., samp_file='samples_5_4_2019.csv' )\n",
    "# Make sure the archive measurement file is in your HOLE directory. \n",
    "# Note:  this program will not run if the file is in use\n",
    "\n",
    "if srm_archive_file:\n",
    " \n",
    "    comp_depth_key='Depth CSF-B (m)'\n",
    "\n",
    "    convert.iodp_srm_lore(srm_archive_file,meas_file='srm_arch_measurements.txt', comp_depth_key=comp_depth_key,\\\n",
    "                  dir_path=magic_dir,input_dir_path=srm_archive_dir,lat=hole_lat,lon=hole_lon)\n",
    "    if 'srm_arch_measurements.txt' not in meas_files:meas_files.append('srm_arch_measurements.txt')\n",
    "    if 'srm_arch_specimens.txt' not in spec_files:spec_files.append('srm_arch_specimens.txt')\n",
    "    if 'srm_arch_samples.txt' not in samp_files:samp_files.append('srm_arch_samples.txt')\n",
    "    if 'srm_arch_sites.txt' not in site_files:site_files.append('srm_arch_sites.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing of SRM archive data.\n",
    "\n",
    "\n",
    "- filter for desired demag step (set in the preliminaries cell). \n",
    "- remove data from within 80 cm of core tops and 10 cm from section ends.\n",
    "- if desired: (set nodist=True), remove from \"disturbed\" intervals labled \"high\" from DescLogic. \n",
    "    - go to DescLogic and export the list of disturbances for the hole.\n",
    "    - put this in HOLE_disturbances.xlsx in the HOLE directory. note that HOLE is your hole name, set in the \"preliminaries\" cell. \n",
    "- remove data from disturbed intervals based on the Xrays. You have to create the Xray data file yourself. There is a template for this that must be followed in PmagPy/data_files/iodp_magic \n",
    "- adjust the data to average normal dec=90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to execute this cell, set False to True. turn it back to False so you don't rerun this by accident. \n",
    "\n",
    "remove_ends=True\n",
    "remove_desclogic_disturbance=False\n",
    "remove_xray_disturbance=False\n",
    "\n",
    "# change the default removal options here: \n",
    "core_top=80 # remove top 80 cm of core top - change as desired\n",
    "section_ends=10 # remove 10 cm from either end of the section - change as desired\n",
    "\n",
    "if False:\n",
    "    arch_demag_step=iodp_funcs.demag_step(magic_dir,hole,demag_step)    # pick the demag step\n",
    "    if remove_ends:\n",
    "        noends=iodp_funcs.remove_ends(arch_demag_step,hole,\\\n",
    "                                      core_top=core_top,section_ends=section_ends) # remove the ends\n",
    "    else:\n",
    "        noends=arch_demag_step\n",
    "    if remove_desclogic_disturbance:\n",
    "        nodist=iodp_funcs.remove_disturbance(noends,hole) # remove coring disturbances\n",
    "    else: \n",
    "        nodist=noends\n",
    "    if remove_xray_disturbance: \n",
    "        no_xray_df=iodp_funcs.no_xray_disturbance(nodist,hole)\n",
    "    else:\n",
    "        no_xray_df=nodist\n",
    "    adj_dec_df,core_dec_adj=iodp_funcs.adj_dec(no_xray_df,hole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='discretes'></a>\n",
    "\n",
    "### Convert SRM discrete sample data to MagIC:\n",
    "- download data for a single hole from LORE as a csv file.\n",
    "    - for OFFLINE treatments (ARM,IRM, DTECH AF, thermal), download both the \n",
    "      \"standard\" and the extended file names\n",
    "- put the file into the HOLE/SRM_discrete_data directory in the HOLE directory\n",
    "- for \"regular\" SRM files (no offline treaments) edit the file name and execute the cell below:\n",
    "- filenames are set in the preliminaries cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if srm_discrete_file:\n",
    "\n",
    "    convert.iodp_dscr_lore(srm_discrete_file,meas_file='srm_dscr_measurements.txt', \\\n",
    "                  dir_path=magic_dir,input_dir_path=srm_discrete_dir,spec_file='lims_specimens.txt')\n",
    "    if 'srm_dscr_measurements.txt' not in meas_files:meas_files.append('srm_dscr_measurements.txt')\n",
    "    dscr_file='srm_dscr_measurements.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for OFFLINE treatments: specify the extended discrete srm file name.\n",
    "\n",
    "NB:  for this to work properly, you must follow these conventions when running the SRM in \n",
    "Offline mode: \n",
    "\n",
    "put these in your comment field in the IMS-10 program for discrete samples:\n",
    "- for NRMs: \n",
    "NRM \n",
    "- for AF demag at 10 mT (for example)\n",
    "AF:10\n",
    "- for thermal at 200 C\n",
    "T:200\n",
    "- for ARM with 100mT AC and 50 uT DC:\n",
    "ARM:100:.05\n",
    "- for IRM in 1000 mT\n",
    "IRM:1000\n",
    "\n",
    "set the filenames in the prelimaries cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dscr_ex_file and srm_discrete_file:\n",
    "\n",
    "\n",
    "    convert.iodp_dscr_lore(srm_discrete_file,dscr_ex_file=dscr_ex_file,meas_file='srm_dscr_measurements.txt', \\\n",
    "                  dir_path=magic_dir,input_dir_path=srm_discrete_dir,spec_file='lims_specimens.txt',\\\n",
    "                      offline_meas_file='srm_dscr_offline_measurements.txt')\n",
    "    if 'srm_dscr_measurements.txt' not in meas_files:meas_files.append('srm_dscr_measurements.txt')\n",
    "    if 'srm_dscr_offline_measurements.txt' not in meas_files:meas_files.append('srm_dscr_offline_measurments.txt')\n",
    "    ipmag.combine_magic(['srm_dscr_measurements.txt','srm_dscr_offline_measurements.txt'],\n",
    "                        outfile='dscr_measurements.txt',dir_path=magic_dir)\n",
    "    dscr_file='dscr_measurements.txt'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make some quickie zijderveld plots in the notebook set the following the True.  To save all the plots, set save_plots to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dscr_file:\n",
    "    ipmag.zeq_magic(meas_file=dscr_file,\\\n",
    "                spec_file='lims_specimens.txt',input_dir_path=magic_dir,n_plots=\"all\",save_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did a bunch of full demagnetizations, set max_field to your maximum af field.  To save your plots, set save_plots to True.  To change the output format, change 'svg' to whatever you want ('pdf','eps','png').  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=1\n",
    "max_field=0 # set this to your peak field (in tesla) to execute this\n",
    "\n",
    "if max_field:\n",
    "    srm_dscr_df=pd.read_csv(magic_dir+'/'+dscr_file,sep='\\t',header=1)\n",
    "    srm_dmag=srm_dscr_df[srm_dscr_df.treat_ac_field>=max_field] # find all the demag specimens\n",
    "    spc_list=srm_dmag.specimen.unique()\n",
    "\n",
    "    for spc in spc_list:\n",
    "        ipmag.zeq_magic(meas_file=dscr_file,specimen=spc,fignum=cnt,\\\n",
    "                spec_file='lims_specimens.txt',input_dir_path=magic_dir,save_plots=False,\n",
    "                       fmt='svg')\n",
    "        cnt+=3;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the JR6 data.  \n",
    "- download the JR6 data from LIMS and put it in the JR6_data folder in your working directory.\n",
    "- edit the file name in the preliminaries cell to reflect the actual file name.  \n",
    "- execute the two cells in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if jr6_file:\n",
    "    convert.iodp_jr6_lore(jr6_file,meas_file='jr6_measurements.txt',dir_path=magic_dir,\\\n",
    "                     input_dir_path=jr6_dir,spec_file='lims_specimens.txt',noave=False)\n",
    "    if 'jr6_measurements.txt' not in meas_files:meas_files.append('jr6_measurements.txt')\n",
    "    dscr_file='jr6_measurements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# combine srm and jr6 data, we can combine the data here:\n",
    "if jr6_file and srm_discrete_file:\n",
    "    ipmag.combine_magic(['srm_dscr_measurements.txt','jr6_measurements.txt'],\n",
    "                        outfile='dscr_measurements.txt',dir_path=magic_dir)\n",
    "    dscr_file='dscr_measurements.txt'\n",
    "max_field=0 # set this to your peak field (in tesla) to execute this\n",
    "if max_field:\n",
    "    cnt=1\n",
    "    dscr_df=pd.read_csv(magic_dir+'/dscr_measurements.txt',sep='\\t',header=1)\n",
    "    dmag_df=dscr_df[dscr_df.treat_ac_field>=max_field] # find all the demag specimens\n",
    "    spc_list=dmag_df.specimen.unique()\n",
    "\n",
    "    for spc in spc_list:\n",
    "        ipmag.zeq_magic(meas_file='dscr_measurements.txt',specimen=spc,fignum=cnt,\\\n",
    "                spec_file='lims_specimens.txt',input_dir_path=magic_dir,save_plots=False)\n",
    "        cnt+=3;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aniso'></a>\n",
    "\n",
    "###  AMS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert AMS data to MagIC\n",
    "\n",
    "- Download KAPPABRIDGE expanded magnetic susceptibility data from the Lims Online Repository\n",
    "- place the downloaded .csv file in the KLY4S_data in the HOLE directory.  \n",
    "- change kly4s_file to the correct file name in the preliminaries cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if kly4s_file:\n",
    "    convert.iodp_kly4s_lore(kly4s_file, meas_out='kly4s_measurements.txt', \n",
    "           spec_infile='lims_specimens.txt', spec_out='kly4s_specimens.txt',\n",
    "           dir_path=magic_dir, input_dir_path=kly4s_dir,actual_volume=7)\n",
    "    if 'kly4s_measurements.txt' not in meas_files:meas_files.append('kly4s_measurements.txt')\n",
    "    if 'kly4s_specimens.txt' not in meas_files:meas_files.append('kly4s_specimens.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a depth plot of your AMS data, change the False to True in the cell below and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    ipmag.ani_depthplot(spec_file='kly4s_specimens.txt', dir_path=magic_dir, \n",
    "                    samp_file='lims_samples.txt',site_file='lims_sites.txt',\n",
    "                   dmin=-1,dmax=-1,meas_file='kly4s_measurements.txt',\n",
    "                   sum_file=core_summary_file)\n",
    "    plt.savefig('Figures/'+hole+'_anisotropy_xmastree.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way makes equal area plots in core coordinates.... To run it, set the False to True.\n",
    "To save the plots, sset save_plots to True.  for different options, try (help(ipmag.aniso_magic_nb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    ipmag.aniso_magic_nb(infile=magic_dir+'/kly4s_specimens.txt',\\\n",
    "                     verbose=False,save_plots=False,ihext=False,iboot=True,ivec=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plots'></a>\n",
    "\n",
    "### Downhole Plots\n",
    "\n",
    "- Fill in the section summary file in the preliminaries folder and run  the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dscr_file: # checks for discrete measurements, adds depths, etc. \n",
    "    srm_dscr_df=pd.read_csv(magic_dir+'/'+dscr_file,sep='\\t',header=1)\n",
    "    dscr_df=srm_dscr_df.copy(deep=True)\n",
    "    dscr_df=dscr_df[srm_dscr_df['treat_ac_field']==demag_step]\n",
    "    depth_data=pd.read_csv(magic_dir+'/lims_sites.txt',sep='\\t',header=1)\n",
    "    depth_data['specimen']=depth_data['site']\n",
    "    depth_data=depth_data[['specimen','core_depth']]\n",
    "    depth_data.sort_values(by='specimen')\n",
    "    dscr_df=pd.merge(dscr_df,depth_data,on='specimen')\n",
    "else:\n",
    "    dscr_df=\"\" # if no discrete samples.  \n",
    "\n",
    "if section_summary_file:\n",
    "    arch_demag_step=pd.read_csv(hole+'/'+hole+'_arch_demag_step.csv')\n",
    "    adj_dec_df=pd.read_csv(hole+'/'+hole+'_dec_adjusted.csv')\n",
    "#Let's get the section boundaries.  \n",
    "# edit the file name for the Section Summary table downloaded from LIMS\n",
    "\n",
    "\n",
    "    summary_df=pd.read_csv(summary_file)\n",
    "    summary_df.dropna(subset=['Sect'],inplace=True)\n",
    "    if type(summary_df.Sect)!='str':\n",
    "        summary_df.Sect=summary_df.Sect.astype('int64')\n",
    "        summary_df.Sect=summary_df.Sect.astype('str')\n",
    "\n",
    "    summary_df=summary_df[summary_df['Sect'].str.contains('CC')==False]\n",
    "    max_depth=arch_demag_step['core_depth'].max()\n",
    "\n",
    "    summary_df=summary_df[summary_df['Top depth CSF-A (m)']<max_depth]\n",
    "    sect_depths=summary_df['Top depth CSF-A (m)'].values\n",
    "    summary_df['Core']=summary_df['Core'].astype('int')\n",
    "    labels=summary_df['Core'].astype('str')+summary_df['Type']+'-'+summary_df['Sect'].astype('str')\n",
    "\n",
    "    arch_demag_step=pd.read_csv(hole+'/'+hole+'_arch_demag_step.csv')\n",
    "    interval=100 # how to divide up the plots\n",
    "    depth_min,depth_max=0,interval\n",
    "    fignum=1\n",
    "    while depth_min<arch_demag_step.core_depth.max():\n",
    "        iodp_funcs.make_plot(arch_demag_step,adj_dec_df,sect_depths,hole,\\\n",
    "                         gad_inc,depth_min,depth_max,labels,spec_df=dscr_df,fignum=fignum)\n",
    "        depth_min+=interval\n",
    "        depth_max+=interval\n",
    "        fignum+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "\n",
    "###  Tidy up for MagC\n",
    "\n",
    "Combine all the MagIC files for uploading to MagIC (http://earthref.org/MagIC).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # when ready to upload, you can set this to true to make upload file. \n",
    "    ipmag.combine_magic(spec_files,outfile='specimens.txt',dir_path=magic_dir)\n",
    "    ipmag.combine_magic(samp_files,outfile='samples.txt',dir_path=magic_dir)\n",
    "    ipmag.combine_magic(site_files,outfile='sites.txt',dir_path=magic_dir)\n",
    "    ipmag.combine_magic(meas_files,outfile='measurements.txt',dir_path=magic_dir)\n",
    "    ipmag.upload_magic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
